{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Sequence, Union\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key difference here is that we remove canonical_ids = np.arange(558).reshape(-1, 1)\n",
    "def create_hdf5_file(\n",
    "    specimens_data: List[np.ndarray],\n",
    "    output_path: Path,\n",
    "    file_prefix: str = \"specimen\",\n",
    "    start_idx: int = 0,\n",
    ") -> int:\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with h5py.File(output_path, \"w\") as f:\n",
    "        specimens_group = f.create_group(\"specimens\")\n",
    "\n",
    "        for i, specimen_data in enumerate(specimens_data):\n",
    "            specimen_key = f\"{file_prefix}_{start_idx + i:06d}\"\n",
    "            specimens_group.create_dataset(specimen_key, data=specimen_data.astype(np.float32))\n",
    "\n",
    "        f.attrs[\"num_specimens\"] = len(specimens_data)\n",
    "        f.attrs[\"format_version\"] = \"1.1\"\n",
    "        f.attrs[\"description\"] = \"C. elegans nuclei data: [canonical_id, x, y, z]\"\n",
    "\n",
    "    return start_idx + len(specimens_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33036f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we do not have the shuffling and splitting of the dataset because it all refers to the test set\n",
    "def convert_specimens_to_hdf5(\n",
    "    specimens_data: Union[np.ndarray, Sequence[np.ndarray]],\n",
    "    output_dir: Union[str, Path],\n",
    "    specimens_per_file: int = 2**14,\n",
    ") -> None:\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    specimens_list = list(specimens_data)\n",
    "\n",
    "    split_dir = output_dir / \"test\"\n",
    "    split_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    file_idx = 0\n",
    "    specimen_idx = 0\n",
    "\n",
    "    for start_idx in range(0, len(specimens_list), specimens_per_file):\n",
    "        end_idx = min(start_idx + specimens_per_file, len(specimens_list))\n",
    "        batch_data = specimens_list[start_idx:end_idx]\n",
    "\n",
    "        file_path = split_dir / f\"test_{file_idx:04d}.h5\"\n",
    "        specimen_idx = create_hdf5_file(\n",
    "            batch_data,\n",
    "            file_path,\n",
    "            file_prefix=\"specimen\",\n",
    "            start_idx=specimen_idx,\n",
    "        )\n",
    "        file_idx += 1\n",
    "\n",
    "    info = {\n",
    "        \"total_specimens\": len(specimens_list),\n",
    "        \"split\": \"test\",\n",
    "        \"specimens_per_file\": specimens_per_file,\n",
    "        \"format\": \"[canonical_id, x, y, z]\",\n",
    "    }\n",
    "\n",
    "    with open(output_dir / \"dataset_info.json\", \"w\") as f:\n",
    "        json.dump(info, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef99221",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_worm_1_pickle_path = Path(\"/fs/pool/pool-mlsb/bulat/Wormologist/synthetic_data_generator/test1worms.pkl\")\n",
    "test_worm_2_pickle_path = Path(\"/fs/pool/pool-mlsb/bulat/Wormologist/synthetic_data_generator/test2worms.pkl\")\n",
    "subgraph_output_directory = Path(\"/fs/pool/pool-mlsb/bulat/Wormologist/new_subgraph_testing_data\")\n",
    "subgraph_output_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5db8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "specimens_per_file = 2**14\n",
    "rng_seed = 42\n",
    "test_sizes = np.array(list(range(10, 560, 10)) + [558])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_worm_1_pickle_path, \"rb\") as f:\n",
    "    worm1 = pickle.load(f)\n",
    "with open(test_worm_2_pickle_path, \"rb\") as f:\n",
    "    worm2 = pickle.load(f)\n",
    "all_worms = worm1 + worm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "for subgraph_size in test_sizes:\n",
    "    subgraph_samples: List[np.ndarray] = []\n",
    "\n",
    "    for answer, coords in all_worms:\n",
    "        nodes = len(answer)\n",
    "        sample_count = int(np.ceil(558 / subgraph_size)) * 2\n",
    "\n",
    "        for _ in range(sample_count):\n",
    "            sampled_indices = rng.choice(nodes, size=min(subgraph_size, nodes), replace=False)\n",
    "            canonical_ids = np.asarray(answer)[sampled_indices]\n",
    "            coords_subset = np.asarray(coords)[sampled_indices]\n",
    "\n",
    "            sample = np.zeros((len(sampled_indices), 4), dtype=np.float32)\n",
    "            sample[:, 0] = canonical_ids.astype(np.float32)\n",
    "            sample[:, 1:] = coords_subset.astype(np.float32)\n",
    "            subgraph_samples.append(sample)\n",
    "\n",
    "    subgraph_dir = subgraph_output_directory / f\"subgraph_{int(subgraph_size):03d}\"\n",
    "    \n",
    "    convert_specimens_to_hdf5(\n",
    "        subgraph_samples,\n",
    "        output_dir=subgraph_dir,\n",
    "        specimens_per_file=specimens_per_file,\n",
    "    )\n",
    "    print(f\"Saved {len(subgraph_samples)} subgraphs of size {subgraph_size} to {subgraph_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677af9c-edbf-4179-a814-275efca955d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
